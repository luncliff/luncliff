
goorm COMMIT 행사 발표의 청취노트입니다.

- 구름 기술 블로그 https://tech.goorm.io/commit/
- 구름 COMMIT 세미나 목록 https://tech.goorm.io/category/commit-ko/seminar-ko/

**Comm**unication + **IT**: 기술, 개발, 성장, 조직문화

# AI 코딩 에이전트, 더 똑똑하게 쓰기(Smarter Ways to Use AI Coding Agents)

- https://tech.goorm.io/2504_commit/
- 당근마켓 - 김대권 님

nacyot 김대권. 44bits 라이트닝 토크 밋업 5월 21일, 판교역 힐스테이트
bit.ly/codingagent

당근마켓 SRE팀 리더, 인프라 담당 첫번째. 10여명까지 팀 빌드업. 매니저 하다보니 번아웃으로 퇴사
2025년에 재입사

### LLM의 세계
Agent 에 대해서 다루기 전에...

긍정과 부정, 사용량: 축 2개. 4분면에서 자신의 현 위치를 파악.
LLM의 환각 문제 때문에 부정적, 경계하는 마음

### 코딩에이전트 등장 이후
커서, 클라인, 깃헙 코파일럿

생각보다 동작을 잘하는데, 왜 잘하지? 어떻게 하면 잘하게 만들 수 있지? 라는 의문이 발표의 중심

커서와 클로드 소넷
mozila/readability - 웹페이지의 컨텐츠만 뽑아서 읽기 좋게 만들어주는 라이브러리
웹에서 쓰기 좋게 만들어서 람다로 배포

데드락
* 5년이상 방치된 코드
* 너무 오래된 노드 버전
* AWS 람다 기반 - 지금은 동작하지 않는 툴들 때문에 실행이 어려움
* 실행해보려면 인터페이스부터 뜯어고쳐야...

### 커서를 사용해볼까?

* 어디서 들어는 봤는데... emacs 사용자가 IDE로 전환
커서 컴포저 에이전트 모드.

이게 바이브 코딩? 그냥 말만하면서 제작하는 상태

문법과 같은 자잘한 부분에서 삽질을 하게 된다.
인터페이스 전환에 1시간 정도가 필요했음... 왜 이게 되지?

성공요인
* 커서 컴포저 모드
* 클로드 소넷 3.5

노드와 다른 프레임워크들의 하위호환성

### 어떻게 에이전트 모드가 나올 수 있을까?

사실은 클로드 소넷이 좋은 모델이어서 그런게 아닐까? 2024년 6월, 거의 1년(오래됨?)

클라인 에이전트 설명
* 클로드 3.7 소넷의 에이전트 능력 덕분에, 복잡한 문제를 단계적으로 풀어나갈 수 있다...
* 안드레 카파시, 바이브 코딩 - 컴포저가 너무 좋아지고 있다

### 코딩 에이전트 모델의 조건

* 코드 편집을 위한 포맷팅 능력
* 문제 해결을 위한 에이전틱한 동작 가능
* 도구 사용 가능 - 에디터, 터미널 - LLM이 제대로 동작하기 위한 조건

소넷 3.5 덕분에 이런 변화가 있었던 것 같다

### AI 페어 프로그래밍 in 2025
드라이버와 내비게이터가 자리를 바꿀 필요가 있다
프로그래머가 Driver(코드 편집자)

지금은 프로그래머가 내비게이터. LLM이 드라이버 역할

Vibe Coding?
LLM이 작성한 코드를 검토하지 않고, LLM으로 소프트웨어를 구축하는 것

LLM for code responsibility?
책임감 있게 작성하는 코드?

### 개인적으로 프로젝트를 진행해보고 있음

URL을 등록하면, 그 정보를 읽어와서 내용 분석, 요약, 아카이브, 북마킹 등

* Roo Code
* 클로드 소넷 3.5, 3.7 사용

14k 정도까지는 어느정도 납득

### 5가지 질문 혹은 배움

그런데 갑자기 Roo Code?

* 왜 커서가 아닌가요?
* 모델은 어떤걸 선택하나요?
* 프롬프트는 어떻게 써야하나요?
* 내 에이전트는 왜 알아서 동작하지 않나요?
* YOLO 모드를 쓰면 알아서 하는거 아닌가요?

컨텍스트 윈도우 - ChatCompletion API

이 API를 보면 messages 가 제일 중요, 그런데 LLM API는 stateless하다.
LLM 앱을 써보면 어떻게든 기억을 해주던데?
LLM의 기억력이 느껴진다면 그것은 착각. API를 보면 이전에 누적된 message들을 전송하거나, 요약해서 보내줘야 한다
이것이 context window 문제. LLM의 작업 메모리


tiktokenizer.vercel.app
토큰을 쪼개서 보내는 방식. LLM을 학습하면서 결정되기 때문에 예측하기는 어렵다.
그리고 모델들은 받아들일 수 있는 최대 크기가 정해져있다
* 지원하는 토큰 수 12만, 20만, 100만 등... 굉장히 큰 숫자.
보통은 아웃풋 토큰을 보지만, 실제로 사용하다보면 인풋 토큰을 굉장히 많이 쓰게 된다. 이 소비량이 비용에 영향을 주기도
하나의 세션이 길어지면? 인풋 비용이 커진다.

특히 코딩에이전트는 입력이 많다
* 파일 목록, 파일 내용, 문서, 컨텍스트, 수정사항 등 모두 전달
* 커서의 컨텍스트 윈도우 관리 전략은 비공개 --> 커뮤니티의 불만(내 말을 잊어버리거나, 무시한다)

컨텍스트 제한?
* 코딩 에이전트에서 이는 결국 진행중인 작업을 잊어버리는 문제

Roo Code는 Cline보다 조금 더 커스텀이 가능함
클로드 3.7과 함께 사용하면 많은 입력을 사용

컨텍스트 윈도우 문제 --> max 모드 출시. 또 다른 과금체계를 가지고 있다
모델의 성능 활용은 비싸다... 그런만큼 컨텍스트 윈도우를 최대한 활용해야 함

### 코딩 에이전트

인터페이스, 시스템 프롬프트, 컨텍스트 관리 전략, 도구

취향의 영역도 있는데...
* 시스템 프롬프트도 결국 긴 텍스트

개인적으로는 루 코드, 클로드 코드 추천

### 모델은 어떻게 선택?

LLM model은 두뇌, 최소한 소넷 3.5보단 좋아야 한다고 생각함
3.7, GPT 4o...

요즘 모델들 다 많이 나오는데, 파악하기가 어렵다.
Aider LLM Leaderboards 를 참고해서 결정할수 있음

프론티어 모델들은 비용 문제가 있음
제미니 2.5 프로는 저렴하고 순위도 높은 편. 그런데 그러면 바로 쓰면 되나?
모델들은 서로 다르게 동작하고, 개성이 있다

Q. 시스템 프롬프트와 사용자 프롬프트에 상반된 요청을 넣고 동작시키면?
무조건 시스템 프롬프트를 우선하는 경우가 발생. (사용자 무시)

아직은 소넷 3.7이 검증+가성비 라는 느낌

### 프롬프트는 어떻게 쓰지?

적절한 작업 단위는 어떻게 되는가?

사람과는 다르게 애매모호한 지시를 내리는 경우가 많음

LLM이 스스로 구조를 파악하는 경우, 잘못 동작할 가능성이 높아진다.
루비 온 레일즈의 설정보다 관례
--> 맥락 전달

개인적으로 사용하는 기법 (사용자 프롬프트)
* 해결해야 하는 문제, 해결할 문제가 아닌 것의 구분(Goal, Non Goal)
* 강조 사항이나 사전 작업 등을 지시

컨텍스트 윈도우 크기가 너무 크면 비용이 크고 응답이 늦어지기도

시스템 프롬프트에 많은 내용이 있어서 너무 추상적이지 않으면 잘 동작한다.
부작용이나 영향범위에 대해서도 전달
스니펫 앱이나 확장을 사용하는 방법

### 프롬프트와 컨텍스트 관리

사용자 프롬프트로 작성할지 고민
* 강조사항, 사전작업

에이전트가 문제를 해결하는 공간을 최적화 한다

파일 읽기에 실패하면, 만들지 말고 검색해볼 것
프롬프트 전에 테스트를 실행하도록 조정할수도. 테스트 실행 전에 컨텍스트를 공부하도록 지시

사용자 프롬프트가 최선인가? 프롬프트와 컨텍스트 개입

* 사용자 프롬프트 (진입점) - 그때 그때 동적으로 변경
* 시스템 프롬프트 (사전정의) - 커서 rules
* MCP 피드백 - 작업 도중에 추가 context 제공
* 코멘트 - 파일에 대한 컨텍스트를 동적으로 사용

컨텍스트 개입
* 규칙이 많다고 좋은 것은 아니다
  * 컨텍스트 윈도우가 커지고, 입력 토큰 소모가 증가
  * 최소한만 액티브하게 유지 (적용 범위, 규칙 숫자)
* 모든 내용을 지키지는 않게 된다
  * 모델에 따라서 동작이 일관적이지 않음

### 내 에이전트는 왜 알아서 동작하지 않나요?

MCP에 있는 대부분의 기능은 터미널 명령으로 해결 가능
명령 실행 이후 피드백을 받도록 만들기?

코드를 실행할 수 있어야 제대로 동작하는지 확인이 가능하다.
없는 메서드나 코드를 만들지 않도록 환각 방지에 유용

터미널을 사용할 수 없다면 코드 실행이 불가 --> 문제 해결이 되었다거나 불가능이라고 판단하게 됨
명령어 종료 지점을 구분하지 못하는 경우가 있음

개발환경 구축
* 이제는 개발자와 에이전트가 함께 사용하는 환경 구축이 중요
* 파이썬 없이 파이썬 프로그래밍은 불가. 의존성, 사전 준비작업 등이 필요

테스트 사용
* 더 정교하고 더 강력한 피드백이 가능하다
* 이렇게 않으면 사람이 피드백을 줘야하고, 적절한 피드백이 없으면 환각 문제가 발생하게 된다
  * 코드 작성과 테스트 실행이 서로 반복되도록, 테스트가 통과할 때까지 반복하도록 만드는 것
* 문제 해결의 과정을 모니터링
* 단위테스트, 회귀테스트(regression)

피드백을 개선하기 위한 전략?
* 피드백이 잘 동작하는 환경이 있을까? --> 로그나 터미널 출력을 피드백으로 전달

그래도 손으로 확인하는 작업은 아직 필요

### YOLO 모드?

커서에서 사용자의 승인을 받도록 하고 있는데, 그 부분을 생략하도록 하는 것

개발환경이나 테스트 환경 구축은 필수
LLM은 똑똑하고, 그만큼 이상한 동작을 많이 한다. (창의적?)

격리된 개발환경 - Dev container를 사용하는 방법도 좋다고 생각됨
Dev Container는 처음 셋업이 어렵다. 프로젝트마다 설정해야 하는 번거로움과 복잡함

### 왜 잘 동작할 수 있었을까?

LLM 은 두뇌 - 모델 + 메세지

에이전트 - 인터페이스, 시스템 프롬프트, 컨텍스트 윈도우 관리 등등 작업환경(답을 찾아가는게 가능)
피드백 루프 덕분에 상상 이상으로 쓰기 좋아진다고 생각함

작업환경과 피드백을 계속해서 개선해주는 것이 유용하다고 판단됨
Q. LLM이 얼마나 좋은 환경에서 일하고 있지?

### 프로그래머의 역할

* 코딩
* 프롬프트 개선
* 개발환경
* 컨텍스트 관리
* 테스트

코딩 에이전트의 작업 환경을 개선하고 LLM의 능력을 끌어내는 역할
다만 지금은 가능성의 경계를 실험

특정 언어, 팀 프로젝트 도입 등... 모두 돈을 쓰면서 실험하는 상황
실험과 경험에 따라서 완전히 다른 인식

코딩의 비용이 줄어들면 좋은 점? 필요하고 원하는 것에 집중해서 만들 수 있다
더 크고 무서운 변화? 3개월에서 6개월 후에는 코드 90%를 AI 가 작성 (시기는 좀 다를 수 있겠지만?)

The end of programming as we know it


----

최근 소속된 개발팀의 지식들을 프롬프트로 바꾸는 작업을 진행하고 있는데...
그런데 프로젝트들의 구조, 개발환경에 대해서 개발자들간의 인식차이가 굉장히 크다.
부정적이거나 보수적인 팀원들을 바꿀정도의 경험을 만들 수 있는가?
